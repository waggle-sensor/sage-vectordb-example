version: '3.4'
services:
  weaviate:
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    image: semitechnologies/weaviate:1.32.0 #https://weaviate.io/developers/weaviate/release-notes#weaviate-core-and-client-releases
    ports:
      - 8080:8080
      - 50051:50051
    restart: on-failure:0
    environment: #https://weaviate.io/developers/weaviate/config-refs/env-vars
      BIND_INFERENCE_API: 'http://multi2vec-bind:8080'
      RERANKER_INFERENCE_API: http://reranker-transformers:8080
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'multi2vec-bind'
      ENABLE_MODULES: 'multi2vec-bind,reranker-transformers'
      CLUSTER_HOSTNAME: 'node1'
      ASYNC_INDEXING: 'true' #https://weaviate.io/developers/weaviate/concepts/vector-index#asynchronous-indexing
      USE_BLOCKMAX_WAND: 'true' #https://weaviate.io/blog/weaviate-1-18-release#improvements-to-bm25-and-hybrid-search
      USE_INVERTED_SEARCHABLE: 'true'
      # LOG_LEVEL: 'debug' #default is info
      # PROMETHEUS_MONITORING_ENABLED: true #https://weaviate.io/developers/weaviate/configuration/monitoring 
      # PROMETHEUS_MONITORING_PORT: 2112

  multi2vec-bind:
    image: semitechnologies/multi2vec-bind:imagebind
    environment:
      ENABLE_CUDA: 1 #enabling cuda causes, AssertionError: Torch not compiled with CUDA enabled
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
      
  reranker-transformers:
    image: semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2
    environment:
      ENABLE_CUDA: 1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  triton:
    build: 
      context: ./triton
    ports:
      - 8000:8000
      - 8001:8001 
      - 8002:8002
    shm_size: '500MB'  #shared memory size
    restart: on-failure
    runtime: nvidia 
    environment:
      - MODEL_REPOSITORY=/app/models  # Ensure this path matches the model repository directory 
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  gradio-ui:
    build:
      context: ./app
    ports:
      - 7860:7860
    restart: on-failure
    environment:
      WEAVIATE_HOST: 'weaviate'
      WEAVIATE_PORT: '8080'
      WEAVIATE_GRPC_PORT: '50051'
      CLUSTER_FLAG: 'True'
    labels:
      com.docker.compose.override: 'always-rebuild' #this can be removed, just have it for development